{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "738bf5c0-9f7b-43f5-b5d5-37df84256403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import glob\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6458880-8e60-4cbf-b544-ea84ba06cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATASET\n",
    "\n",
    "# Define the folders\n",
    "folders = {\"Blanks\": \"small_animals/Blanks\", \n",
    "           \"American_Toad\": \"small_animals/American_Toad\", \"Green_Frog\": \"small_animals/Green_Frog\", \n",
    "           \"Northern_Leopard_Frog\": \"small_animals/Northern_Leopard_Frog\", \"Common_Yellowthroat\": \"small_animals/Common_Yellowthroat\",\n",
    "           \"Indigo_Bunting\": \"small_animals/Indigo_Bunting\", \"Northern_House_Wren\": \"small_animals/Northern_House_Wren\",\n",
    "           \"Song_Sparrow\": \"small_animals/Song_Sparrow\", \"Sora\": \"small_animals/Sora\", \"Invertebrate\": \"small_animals/Invertebrate\",\n",
    "           \"Common_Five-linked_skink\": \"small_animals/Common_Five-linked_skink\", \"American_Mink\": \"small_animals/American_Mink\",\n",
    "           \"Eastern_Chipmunk\": \"small_animals/Eastern_Chipmunk\", \"Eastern_Cottontail\": \"small_animals/Eastern_Cottontail\", \n",
    "           \"Long_tailed_Weasel\": \"small_animals/Long_tailed_Weasel\", \"Masked_Shrew\": \"small_animals/Masked_Shrew\", \n",
    "           \"Meadow_Jumping_Mouse\": \"small_animals/Meadow_Jumping_Mouse\", \"Meadow_Vole\": \"small_animals/Meadow_Vole\", \n",
    "           \"N._Short-tailed_Shrew\": \"small_animals/N._Short-tailed_Shrew\", \"Raccoon\": \"small_animals/Raccoon\", \n",
    "           \"Star-nosed_mole\": \"small_animals/Star-nosed_mole\", \"Striped_Skunk\": \"small_animals/Striped_Skunk\", \n",
    "           \"Virginia_Opossum\": \"small_animals/Virginia_Opossum\", \"White-footed_Mouse\": \"small_animals/White-footed_Mouse\", \n",
    "           \"Woodchuck\": \"small_animals/Woodchuck\", \"Woodland_Jumping_Mouse\": \"small_animals/Woodland_Jumping_Mouse\", \n",
    "           \"Butler's_Gartersnake\": \"small_animals/Butler's_Gartersnake\", \"Dekay's_Brownsnake\": \"small_animals/Dekay's_Brownsnake\", \n",
    "           \"Eastern_Gartersnake\": \"small_animals/Eastern_Gartersnake\", \"Eastern_Hog-nosed_snake\": \"small_animals/Eastern_Hog-nosed_snake\", \n",
    "           \"Eastern_Massasauga\": \"small_animals/Eastern_Massasauga\", \"Eastern_Milksnake\": \"small_animals/Eastern_Milksnake\", \n",
    "           \"Eastern_Racer_Snake\": \"small_animals/Eastern_Racer_Snake\", \"Eastern_Ribbonsnake\": \"small_animals/Eastern_Ribbonsnake\", \n",
    "           \"Gray_Ratsnake\": \"small_animals/Gray_Ratsnake\", \"Kirtland's_Snake\": \"small_animals/Kirtland's_Snake\", \n",
    "           \"Northern_Watersnake\": \"small_animals/Northern_Watersnake\", \"Plains_Gartersnake\": \"small_animals/Plains_Gartersnake\", \n",
    "           \"Smooth_Greensnake\": \"small_animals/Smooth_Greensnake\", \"Turtle\": \"small_animals/Turtle\"\n",
    "        }\n",
    "\n",
    "# Define categories\n",
    "blanks = {\"Blanks\"}\n",
    "invertebrates = {\"Invertebrate\"}\n",
    "lizards = {\"Common_Five-linked_skink\"}\n",
    "turtles = {\"Turtle\" }\n",
    "amphibians = {\"American_Toad\", \"Green_Frog\", \"Northern_Leopard_Frog\" }\n",
    "birds = {\"Common_Yellowthroat\", \"Indigo_Bunting\", \"Northern_House_Wren\", \"Song_Sparrow\", \"Sora\"}\n",
    "mammals = {\"American_Mink\", \"Eastern_Chipmunk\", \"Eastern_Cottontail\", \"Long_tailed_Weasel\", \"Masked_Shrew\", \n",
    "           \"Meadow_Jumping_Mouse\", \"Meadow_Vole\", \"N._Short-tailed_Shrew\", \"Raccoon\", \"Star-nosed_mole\", \n",
    "           \"Striped_Skunk\", \"Virginia_Opossum\", \"White-footed_Mouse\", \"Woodchuck\", \"Woodland_Jumping_Mouse\" }\n",
    "snakes = {\"Butler's_Gartersnake\", \"Dekay's_Brownsnake\", \"Eastern_Gartersnake\", \"Eastern_Hog-nosed_snake\",\n",
    "          \"Eastern_Massasauga\", \"Eastern_Milksnake\", \"Eastern_Racer_Snake\", \"Eastern_Ribbonsnake\", \n",
    "          \"Gray_Ratsnake\", \"Kirtland's_Snake\", \"Northern_Watersnake\", \"Plains_Gartersnake\", \n",
    "          \"Smooth_Greensnake\"}\n",
    "\n",
    "# Dictionary to hold the file paths with their labels\n",
    "file_paths_with_labels = []\n",
    "\n",
    "# Iterate through each folder\n",
    "for label, folder_path in folders.items():\n",
    "    # Get all file paths in the folder\n",
    "    file_paths = glob.glob(os.path.join(folder_path, \"*\"))\n",
    "    \n",
    "    # Append the file paths with their labels\n",
    "    file_paths_with_labels.extend([(file_path, label) for file_path in file_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8d3b249f-c13d-4232-93f7-40f5e9f84ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('small_animals/Blanks/CBNP1N_2020-09-14_20-27-50.JPG', 'Blanks'), ('small_animals/Blanks/CBNP1S_2020-10-22_10-13-15.JPG', 'Blanks')]\n",
      "[('small_animals/Northern_House_Wren/FCM3__2019-08-29__11-28-44(7).JPG', 'Northern_House_Wren'), ('small_animals/Northern_House_Wren/FCM1__2019-08-18__12-16-28(2).JPG', 'Northern_House_Wren')]\n",
      "[('small_animals/Northern_House_Wren/FCM3__2019-08-29__11-28-44(7).JPG', 'Northern_House_Wren'), ('small_animals/Northern_House_Wren/FCM1__2019-08-18__12-16-28(2).JPG', 'Northern_House_Wren')]\n",
      "[('small_animals/Masked_Shrew/NOR3__2019-06-01__19-29-18(4).JPG', 'Masked_Shrew'), ('small_animals/Masked_Shrew/FCM1__2019-06-14__06-57-41(1).JPG', 'Masked_Shrew')]\n",
      "[('small_animals/Eastern_Gartersnake/NOR3__2019-08-31__16-07-08(5).JPG', 'Eastern_Gartersnake'), ('small_animals/Eastern_Gartersnake/KILC4S__2022-10-03__15-23-57(3)__Thamnophis_sirtalis.JPG', 'Eastern_Gartersnake')]\n"
     ]
    }
   ],
   "source": [
    "# Print sample file paths to ensure correctness\n",
    "\n",
    "print(file_paths_with_labels[1500:1502])\n",
    "print(file_paths_with_labels[15000:15002])\n",
    "print(file_paths_with_labels[15000:15002])\n",
    "print(file_paths_with_labels[50000:50002])\n",
    "print(file_paths_with_labels[100000:100002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b723268-ad24-4983-8875-077be21345c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 92943\n",
      "Test set size: 23236\n",
      "Epoch 1/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6133 - loss: 1.3273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 20:30:30.711204: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:64: Filling up shuffle buffer (this may take a while): 566 of 1000\n",
      "2024-12-07 20:30:31.366877: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2581s\u001b[0m 1s/step - accuracy: 0.6134 - loss: 1.3271 - val_accuracy: 0.8117 - val_loss: 0.6040\n",
      "Epoch 2/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 55ms/step - accuracy: 0.8235 - loss: 0.5687 - val_accuracy: 0.8455 - val_loss: 0.4765\n",
      "Epoch 3/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3964s\u001b[0m 2s/step - accuracy: 0.8611 - loss: 0.4371 - val_accuracy: 0.8857 - val_loss: 0.3708\n",
      "Epoch 4/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 56ms/step - accuracy: 0.9054 - loss: 0.2887 - val_accuracy: 0.8912 - val_loss: 0.3428\n",
      "Epoch 5/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 109ms/step - accuracy: 0.9225 - loss: 0.2369 - val_accuracy: 0.9101 - val_loss: 0.2973\n",
      "Epoch 6/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 58ms/step - accuracy: 0.9425 - loss: 0.1746 - val_accuracy: 0.9099 - val_loss: 0.2917\n",
      "Epoch 7/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 345ms/step - accuracy: 0.9489 - loss: 0.1506 - val_accuracy: 0.9175 - val_loss: 0.3254\n",
      "Epoch 8/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 58ms/step - accuracy: 0.9575 - loss: 0.1271 - val_accuracy: 0.9221 - val_loss: 0.2997\n",
      "Epoch 9/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 112ms/step - accuracy: 0.9605 - loss: 0.1164 - val_accuracy: 0.9285 - val_loss: 0.2662\n",
      "Epoch 10/10\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 60ms/step - accuracy: 0.9676 - loss: 0.0959 - val_accuracy: 0.9210 - val_loss: 0.2998\n",
      "\u001b[1m727/727\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "              Green_Frog       0.00      0.00      0.00        15\n",
      "                 Raccoon       0.00      0.00      0.00        12\n",
      "     Eastern_Gartersnake       0.28      0.28      0.28      6443\n",
      "             Meadow_Vole       0.11      0.10      0.11      2760\n",
      "     Eastern_Ribbonsnake       0.00      0.00      0.00        26\n",
      "                    Sora       0.00      0.00      0.00         2\n",
      "      Plains_Gartersnake       0.01      0.01      0.01       266\n",
      " Eastern_Hog-nosed_snake       0.00      0.00      0.00        11\n",
      "       Eastern_Milksnake       0.00      0.00      0.00        13\n",
      "     Common_Yellowthroat       0.01      0.01      0.01       151\n",
      "        Eastern_Chipmunk       0.00      0.00      0.00        35\n",
      "        Kirtland's_Snake       0.00      0.00      0.00         9\n",
      "          Indigo_Bunting       0.00      0.00      0.00         7\n",
      "           American_Toad       0.02      0.01      0.01        75\n",
      "   Northern_Leopard_Frog       0.00      0.00      0.00        32\n",
      "           Gray_Ratsnake       0.00      0.00      0.00         7\n",
      "    Butler's_Gartersnake       0.00      0.00      0.00        26\n",
      "            Song_Sparrow       0.13      0.13      0.13      2996\n",
      "               Woodchuck       0.00      0.00      0.00         9\n",
      "           Striped_Skunk       0.00      0.00      0.00        20\n",
      "  Woodland_Jumping_Mouse       0.00      0.00      0.00       292\n",
      "        Virginia_Opossum       0.00      0.00      0.00       194\n",
      "                  Turtle       0.00      0.00      0.00         8\n",
      "                  Blanks       0.10      0.11      0.10      2354\n",
      "            Invertebrate       0.04      0.04      0.04       978\n",
      "            Masked_Shrew       0.04      0.04      0.04       836\n",
      "      White-footed_Mouse       0.08      0.09      0.08      2043\n",
      "Common_Five-linked_skink       0.04      0.04      0.04      1018\n",
      "   N._Short-tailed_Shrew       0.01      0.01      0.01       142\n",
      "     Northern_House_Wren       0.05      0.05      0.05      1206\n",
      "      Dekay's_Brownsnake       0.01      0.01      0.01       106\n",
      "    Meadow_Jumping_Mouse       0.00      0.00      0.00        28\n",
      "      Eastern_Cottontail       0.03      0.04      0.03       651\n",
      "     Eastern_Racer_Snake       0.00      0.00      0.00        54\n",
      "     Northern_Watersnake       0.00      0.00      0.00        22\n",
      "         Star-nosed_mole       0.00      0.00      0.00        18\n",
      "       Smooth_Greensnake       0.00      0.00      0.00        49\n",
      "           American_Mink       0.03      0.03      0.03        70\n",
      "      Eastern_Massasauga       0.00      0.00      0.00       252\n",
      "\n",
      "                accuracy                           0.13     23236\n",
      "               macro avg       0.03      0.03      0.03     23236\n",
      "            weighted avg       0.13      0.13      0.13     23236\n",
      "\n",
      "\u001b[1m727/727\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9210 - loss: 0.3021\n",
      "Test Accuracy: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    }
   ],
   "source": [
    "# CREATE AND RUN MODEL\n",
    "\n",
    "# Define hyperparameters\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Split data into features (file paths) and labels\n",
    "file_paths, labels = zip(*file_paths_with_labels)\n",
    "\n",
    "# Split into training and testing data\n",
    "train_file_paths, test_file_paths, train_labels, test_labels = train_test_split(file_paths, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "print(\"Training set size:\", len(train_file_paths))\n",
    "print(\"Test set size:\", len(test_file_paths))\n",
    "\n",
    "# Calculate steps per epoch, rounding up\n",
    "#steps_per_epoch = math.floor(len(train_file_paths) / BATCH_SIZE)\n",
    "steps_per_epoch = 2000\n",
    "\n",
    "# Convert labels to integers using the label map\n",
    "label_map = {label: idx for idx, label in enumerate(set(labels))}\n",
    "train_labels = [label_map[label] for label in train_labels]\n",
    "test_labels = [label_map[label] for label in test_labels]\n",
    "\n",
    "# Create TensorFlow dataset from file paths and labels\n",
    "def create_tf_dataset(file_paths, labels, batch_size):\n",
    "    def parse_image(file_path, label):\n",
    "        try:\n",
    "            # Read the image from file\n",
    "            img = tf.io.read_file(file_path)\n",
    "            # Decode the image\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "            # Resize the image to target size\n",
    "            img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "            # Normalize pixel values to [0, 1]\n",
    "            img = img / 255.0\n",
    "            return img, label\n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            # Return None if the image was invalid\n",
    "            return None\n",
    "\n",
    "    # Create a TensorFlow dataset\n",
    "    ds = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "\n",
    "    # Remove invalid images using the filter method\n",
    "    ds = ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.filter(lambda img, label: img is not None)  # Filter out None images\n",
    "\n",
    "    # Shuffle, batch, and prefetch the dataset\n",
    "    ds = ds.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# Create training and testing datasets\n",
    "train_dataset = create_tf_dataset(train_file_paths, train_labels, BATCH_SIZE)\n",
    "test_dataset = create_tf_dataset(test_file_paths, test_labels, BATCH_SIZE)\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(len(label_map), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch\n",
    ")\n",
    "\n",
    "# Get predictions for the test dataset\n",
    "predictions = model.predict(test_dataset)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true labels from the test dataset\n",
    "true_labels = np.array(test_labels)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=list(label_map.keys())))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Save the model\n",
    "tf.keras.models.save_model(model, 'CNN_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9799a-f732-4966-833d-79ed2ea4ba34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
